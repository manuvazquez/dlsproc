# AUTOGENERATED! DO NOT EDIT! File to edit: 10_xml.ipynb (unless otherwise specified).

__all__ = ['get_namespaces', 're_tag', 'split_namespace_tag', 'to_be_skipped', 'get_entries', 'nested_tags_separator',
           'assemble_name', 'unique_name', 'entry_to_dict', 'entry_to_series', 'to_df', 'str_columns',
           'assembled_str_columns', 'post_process', 'to_curated_df', 'columns_depth']

# Cell
import pathlib
import re
import datetime
from collections.abc import Iterable

import numpy as np
import pandas as pd
from lxml import etree

# Cell
def get_namespaces(input_file: str | pathlib.Path, root_name: str = 'base') -> dict:

    tree = etree.parse(input_file)

    namespaces = tree.getroot().nsmap

    if None in namespaces:

        namespaces[root_name] = namespaces.pop(None)

    return namespaces

# Cell
re_tag = re.compile('\{(.*)\}(.*)')

# Cell
def split_namespace_tag(namespace_tag: str) -> str:

    return re_tag.match(namespace_tag).groups()

# Cell
to_be_skipped = ['author', 'id', 'link', 'title', 'updated', r'deleted-entry']
to_be_skipped

# Cell
def get_entries(root: etree.Element) -> list[etree.Element]:

    return [e for e in root if split_namespace_tag(e.tag)[1] == 'entry']

# Cell
nested_tags_separator = ' - '

# Cell
def assemble_name(tags: list) -> str:
    """
    Assemble the name of field/column in the DataFrame from a path of nested tags.

    **Parameters**

    - tags: list

        List of tags.

    **Returns**

    - out: str

        A suitable name.

    """

    # tags = [t for t in tags if not pd.isna(t)]

    tags = filter(pd.notna, tags)
    tags = filter(lambda x: x!='', tags)

    return nested_tags_separator.join(tags)

# Cell
def unique_name(name: str, existing: Iterable[str]):

    tentative = name

    i = 0

    while tentative in existing:

        i += 1
        tentative = f'{name} {i}'.strip()

    return tentative

# Cell
def entry_to_dict(entry: etree.Element, recursive: bool = True) -> dict:

    res = {}

    # for every "child" of `entry` ...
    for e in entry:

        # ...the *namespace* and *tag* are extracted
        namespace, tag = split_namespace_tag(e.tag)

        # for the sake of readability
        value = e.text

        # if `text` is "something" and not an empty string after striping it of blank characteres...
        if value and (value.strip() != ''):

            # if the text contains a number...
            if value.isnumeric():

                # ...it is turned into a `float`
                value = float(value)

                # if the latter is actually an integer...
                if value.is_integer():

                    # ...conversion is performed
                    value = int(value)

            # assert tag not in res, f'multiple values for {tag}'

            # the value of this element (whether the original text or the obtained number) is stored
            res[tag] = value

        # if in "recursive mode" and this element has children (`len(e)` is different from 0)...
        if recursive and len(e):

            # recursion
            sub_res = entry_to_dict(e)

            for k, v in sub_res.items():

                # the name of the new "key" is assembled from those of the parent and the child
                key_name = f'{tag}{nested_tags_separator}{k}'

                # assert key_name not in res, f'multiple values for {key_name}'
                # key_name = unique_name(key_name, res.keys()) # <-------------  a unique name

                res[key_name] = v

    return res

# Cell
def entry_to_series(entry: etree.Element) -> pd.Series:

    return pd.Series(entry_to_dict(entry))

# Cell
def to_df(input_file: str | pathlib.Path) -> pd.DataFrame:
    """
    Reads and parses an XML file into a `pd.DataFrame`.

    **Parameters**

    - input_file: str or Path

        Input file.

    **Returns**

    - out: pd.DataFrame

        A Pandas DataFrame with XML data.

    """

    tree = etree.parse(input_file)
    root = tree.getroot()
    entries = get_entries(root)

    return pd.concat([entry_to_series(e) for e in entries], axis=1).T

# Cell
str_columns = [['ContractFolderStatus', 'LocatedContractingParty', 'Party', 'PostalAddress', 'PostalZone']]

# Cell
assembled_str_columns = [assemble_name(c) for c in str_columns]

# Cell
def post_process(input_df: pd.DataFrame) -> pd.DataFrame:
    """
    Tidy up the `pd.DataFrame` returned by `to_df`.

    **Parameters**

    - input_df: pd.DataFrame

        Input DataFrame as ready by `to_df`.

    **Returns**

    - out: pd.DataFrame

        Post-processed DataFrame.

    """

    res = input_df.copy()

    processed_columns = []

    # ------------ ContractFolderStatus - TenderingProcess - TenderSubmissionDeadlinePeriod ------------

    new_column = assemble_name(['ContractFolderStatus', 'TenderingProcess', 'TenderSubmissionDeadlinePeriod'])

    # we don't want to inadvertently overwrite an existing column
    assert new_column not in res


    res[new_column] = pd.to_datetime(
        input_df[assemble_name(['ContractFolderStatus', 'TenderingProcess','TenderSubmissionDeadlinePeriod','EndDate'])]
        + 'T' +
        input_df[assemble_name(['ContractFolderStatus', 'TenderingProcess','TenderSubmissionDeadlinePeriod','EndTime'])],
        format='%Y-%m-%dT%H:%M:%S', utc=True, errors='coerce'
    )

    processed_columns.append(new_column)

    # -------------------------------------------- updated ---------------------------------------------

    res['updated'] = pd.to_datetime(input_df['updated'], format='%Y-%m-%dT%H:%M:%S.%f%z', utc=True)

    processed_columns.append('updated')

    # ---------------------------------------- string columns ------------------------------------------

    for c in assembled_str_columns:

        if c in res:

            res[c] = res[c].astype(pd.StringDtype())

            processed_columns.append(c)

    # --------------------------------------- everything else ------------------------------------------

    for c in res.columns:

        if c in processed_columns:

            continue

        # an attempt is made...
        try:

            # to interpret every column as a (float) number
            res[c] = res[c].astype(float)


        # if conversion to float is not feasible...
        except (TypeError, ValueError):

            # ...the column is taken to be one of strings
            res[c] = res[c].astype(pd.StringDtype())

    return res

# Cell
def to_curated_df(input_file: str | pathlib.Path) -> pd.DataFrame:
    """
    Reads, parses and tidies up an XML file into a `pd.DataFrame`.

    **Parameters**

    - input_file: str or Path

        Input file.

    **Returns**

    - out: pd.DataFrame

        A Pandas DataFrame with XML data.

    """

    return post_process(to_df(input_file))

# Cell
def columns_depth(df: pd.DataFrame) -> pd.Series:

    n_nestings = df.columns.str.extractall(f'(\\S{nested_tags_separator}\\S)')
    n_nestings.index.names = ['column', 'match']

    return n_nestings[0].groupby('column').size()