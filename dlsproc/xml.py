# AUTOGENERATED! DO NOT EDIT! File to edit: 10_xml.ipynb (unless otherwise specified).

__all__ = ['get_namespaces', 're_tag', 'split_namespace_tag', 'to_be_skipped', 'get_entries', 'nested_tags_separator',
           'assemble_name', 'entry_to_dict', 'entry_to_series', 'flat_series_to_multiindexed_series', 'to_df',
           'flat_df_to_multiindexed_df', 'post_process', 'to_curated_df', 'columns_depth']

# Cell
import pathlib
import re
import datetime

import numpy as np
import pandas as pd
from lxml import etree

# Cell
def get_namespaces(input_file: str | pathlib.Path, root_name: str = 'base') -> dict:

    tree = etree.parse(input_file)

    namespaces = tree.getroot().nsmap

    if None in namespaces:

        namespaces[root_name] = namespaces.pop(None)

    return namespaces

# Cell
re_tag = re.compile('\{(.*)\}(.*)')

# Cell
def split_namespace_tag(namespace_tag: str) -> str:

    return re_tag.match(namespace_tag).groups()

# Cell
to_be_skipped = ['author', 'id', 'link', 'title', 'updated', r'deleted-entry']
to_be_skipped

# Cell
def get_entries(root: etree.Element) -> list[etree.Element]:

    return [e for e in root if split_namespace_tag(e.tag)[1] == 'entry']

# Cell
nested_tags_separator = ' - '

# Cell
def assemble_name(tags: list) -> str:
    """
    Assemble the name of field/column in the DataFrame from a path of nested tags.

    **Parameters**

    - tags: list

        List of tags.

    **Returns**

    - out: str

        A suitable name.

    """

    tags = [t for t in tags if not pd.isna(t)]

    return nested_tags_separator.join(tags)

# Cell
def entry_to_dict(entry: etree.Element, recursive: bool = True) -> dict:

    res = {}

    # for every "child" of `entry` ...
    for e in entry:

        # ...the *namespace* and *tag* are extracted
        namespace, tag = split_namespace_tag(e.tag)

        # for the sake of readability
        value = e.text

        # if `text` is "something" and not an empty string after striping it of blank characteres...
        if value and (value.strip() != ''):

            # if the text contains a number...
            if value.isnumeric():

                # ...it is turned into a `float`
                value = float(value)

                # if the latter is actually an integer...
                if value.is_integer():

                    # ...conversion is performed
                    value = int(value)

            # the value of this element (whether the original text or the obtained number) is stored
            res[tag] = value

        # if in "recursive mode" and this element has children (`len(e)` is different from 0)...
        if recursive and len(e):

            # recursion
            sub_res = entry_to_dict(e)

            for k, v in sub_res.items():

                # the name of the new "key" is assembled from those of the parent and the child
                res[f'{tag}{nested_tags_separator}{k}'] = v

    return res

# Cell
def entry_to_series(entry: etree.Element) -> pd.Series:

    return pd.Series(entry_to_dict(entry))

# Cell
def flat_series_to_multiindexed_series(s: pd.Series) -> pd.Series:

    index_paths = []
    values = []

    for i, v in s.iteritems():
        index_paths.append(tuple(i.split(nested_tags_separator)))
        values.append(v)

    return pd.Series(values, index=pd.MultiIndex.from_tuples(index_paths))

# Cell
def to_df(input_file: str | pathlib.Path) -> pd.DataFrame:
    """
    Reads and parses an XML file into a `pd.DataFrame`.

    **Parameters**

    - input_file: str or Path

        Input file.

    **Returns**

    - out: pd.DataFrame

        A Pandas DataFrame with XML data.

    """

    tree = etree.parse(input_file)
    root = tree.getroot()
    entries = get_entries(root)

    return pd.concat([entry_to_series(e) for e in entries], axis=1).T

# Cell
def flat_df_to_multiindexed_df(input_df: pd.DataFrame) -> pd.DataFrame:
    """
    Reads and parses an XML file into a `pd.DataFrame`.

    **Parameters**

    - input_df: `pd.DataFrame`

        Input dataframe.

    **Returns**

    - out: pd.DataFrame

        A column-hierarchical version of the input dataframe.

    """

    # every column name is turned into a `tuple`, and from the collection of all of them a `pd.MultiIndex` is built
    index_hierarchical = pd.MultiIndex.from_tuples([tuple(c.split(nested_tags_separator)) for c in input_df.columns])

    # an empty `pd.DataFrame`
    res = pd.DataFrame(None, columns=index_hierarchical)

    # every column in the *output* `pd.DataFrame`...
    for c in res.columns:

        # ...is filled in looking up the data in the input `pd.DataFrame` by means of the appropriate "merged" column name
        res[c] = input_df[assemble_name(c)]

    return res

# Cell
def post_process(input_df: pd.DataFrame) -> pd.DataFrame:
    """
    Tidy up the `pd.DataFrame` returned by `to_df`.

    **Parameters**

    - input_df: pd.DataFrame

        Input DataFrame as ready by `to_df`.

    **Returns**

    - out: pd.DataFrame

        Post-processed DataFrame.

    """

    res = input_df.copy()

    processed_columns = []

    # ------------ ContractFolderStatus - TenderingProcess - TenderSubmissionDeadlinePeriod ------------

    new_column = assemble_name(['ContractFolderStatus', 'TenderingProcess', 'TenderSubmissionDeadlinePeriod'])

    # we don't want to inadvertently overwrite an existing column
    assert new_column not in res
    res[new_column] = pd.to_datetime(
        input_df[assemble_name(['ContractFolderStatus', 'TenderingProcess','TenderSubmissionDeadlinePeriod','EndDate'])]
        + 'T' +
        input_df[assemble_name(['ContractFolderStatus', 'TenderingProcess','TenderSubmissionDeadlinePeriod','EndTime'])],
        format='%Y-%m-%dT%H:%M:%S', utc=True
    )

    processed_columns.append(new_column)

    # -------------------------------------------- updated ---------------------------------------------

    res['updated'] = pd.to_datetime(input_df['updated'], format='%Y-%m-%dT%H:%M:%S.%f%z', utc=True)

    processed_columns.append('updated')

    # --------------------------------------- everything else ------------------------------------------

    for c in res.columns:

        if c in processed_columns:

            continue

        res[c] = res[c].astype(pd.StringDtype())

    return res

# Cell
def to_curated_df(input_file: str | pathlib.Path, hierarchical: bool = False) -> pd.DataFrame:
    """
    Reads, parses and tidies up an XML file into a `pd.DataFrame`.

    **Parameters**

    - input_file: str or Path

        Input file.

    - hierarchical: bool

        - If `True` multi-indexed columns are returned.

    **Returns**

    - out: pd.DataFrame

        A Pandas DataFrame with XML data.

    """

    res = post_process(to_df(input_file))

    if hierarchical:

        res = flat_df_to_multiindexed_df(res)

    return res

# Cell
def columns_depth(df: pd.DataFrame) -> pd.Series:

    n_nestings = df.columns.str.extractall(f'(\\S{nested_tags_separator}\\S)')
    n_nestings.index.names = ['column', 'match']

    return n_nestings[0].groupby('column').size()